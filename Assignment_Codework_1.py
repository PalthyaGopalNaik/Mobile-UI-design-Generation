# -*- coding: utf-8 -*-
"""ASSIGNMNT.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rUBoWLtlXmyEGzHKkB1BBhYS2FExkYr2
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# ! pip install datasets
# ! pip install diffusers["torch"] transformers
# ! pip install -U instructor



from getpass import getpass
openai_token = getpass("Enter your OpenAI API token: ")

import openai
import instructor
patched_openai_client = instructor.patch(openai.OpenAI(api_key=openai_token))

from pydantic import BaseModel, Field

class DescriptionPrediction(BaseModel):
    description: str = Field(..., description="Please provide the description based on the tags provided")
    chain_of_thought: str = Field(..., description="Think Step by Step and provide your reasoning for the description")

def get_relavant_description_from_tags(tags: list[str]):
    tags_str = "\n\n".join(tags)
    llm_response = patched_openai_client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": "Please provide the description based on the tags provided"
            },
            {
                "role": "user",
                "content": f"""Here are the tags delimited by ```{tags_str}```"""
            }
        ],
        model="gpt-4o",
        response_model=DescriptionPrediction,
        max_retries=2,
        top_p=1,
        frequency_penalty=0,
        presence_penalty=0,
        temperature=0.1
    )

    return llm_response.description

import os
from datasets import load_dataset
from transformers import AutoTokenizer, AutoModelForCausalLM
from diffusers import StableDiffusionPipeline
import torch

def setup_models():
    tokenizer = AutoTokenizer.from_pretrained("gpt2")
    llm = AutoModelForCausalLM.from_pretrained("gpt2")
    image_model = StableDiffusionPipeline.from_pretrained("runwayml/stable-diffusion-v1-5", torch_dtype=torch.float16)
    image_model.to("cuda" if torch.cuda.is_available() else "cpu")
    return tokenizer, llm, image_model

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
def retrieve_relevant_designs(query, dataset, top_n=5):
    descriptions = []
    try:
        for item in dataset['train']:
            if 'objects' in item and isinstance(item["objects"], dict) and "text" in item["objects"]:
                texts = [text for text in item["objects"]['text'] if text is not None]

                descriptions.append(" ".join(texts))
    except Exception as e:
        print(f"Error retrieving descriptions: {e}")

    else:
        print("Descriptions retrieved successfully.")

    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform([query] + descriptions)

    query_vector = tfidf_matrix[0]
    description_vectors = tfidf_matrix[1:]

    similarities = cosine_similarity(query_vector, description_vectors).flatten()
    top_indices = similarities.argsort()[-top_n:][::-1]

    relevant_designs = [dataset['train'][int(i)] for i in top_indices]
    return relevant_designs

def generate_design_description(query, relevant_designs, tokenizer, llm):
    relevant_texts = []
    for design in relevant_designs:
        if 'objects' in design and isinstance(design["objects"], dict) and "text" in design["objects"]:
            texts = [text for text in design["objects"]['text'] if text is not None]
            try:
                relevant_context = get_relavant_description_from_tags(texts)
            except Exception as e:
                print(f"Error generating description: {e}")
                relevant_context = " ".join(texts)
            relevant_texts.append(relevant_context)

    prompt = f"Generate a mobile UI design based on: {query}. Relevant designs: {' '.join(relevant_texts)}"
    inputs = tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
    outputs = llm.generate(**inputs, max_new_tokens=100, num_return_sequences=1)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def generate_design_image(design_description, image_model):
    image = image_model(design_description).images[0]
    return image



def generate_ui_design(query):
    dataset = load_dataset("mrtoy/mobile-ui-design")
    tokenizer, llm, image_model = setup_models()
    relevant_designs = retrieve_relevant_designs(query, dataset)
    design_description = generate_design_description(query, relevant_designs, tokenizer, llm)
    design_image = generate_design_image(design_description, image_model)
    return design_image, design_description

def main():
    while True:
        query = input("Enter your UI design query (or 'quit' to exit): ")
        if query.lower() == 'quit':
            break
        design_image, design_description = generate_ui_design(query)
        filename = f"generated_design_{hash(query)}.png"
        design_image.save(filename)
        print(f"Design generated and saved as {filename}")
        print(f"Design description: {design_description}")

if __name__ == "__main__":
    main()